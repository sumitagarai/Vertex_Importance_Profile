{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9587df86-722a-46a4-b2e5-6dd3fb3bd26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import bct.algorithms\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "from scipy import stats\n",
    "from tabulate import tabulate\n",
    "import dataframe_image as dfi\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold,cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import random\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ripser import ripser\n",
    "from persim import plot_diagrams\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "import pickle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba088b23-e229-442f-9e37-3408c4b9e82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the fMRI Data in the Matriux Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb52429-2908-48b9-9b3d-e880afb8c6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/sumita/Downloads/Research/NetNeuro/ADNI_fMRI_Frederick_Jiong/fmri-data-fullnetworks/\"\n",
    "subfolders = os.listdir(path)\n",
    "subfolders_cleaned = []\n",
    "# remove unnecessary folders\n",
    "for item in subfolders:\n",
    "    if not item.startswith('.') and not item.startswith('s'):\n",
    "        subfolders_cleaned.append(item)\n",
    "# access func_nets folder for each patient\n",
    "subj_nets = pd.DataFrame(columns=['Subj_ID', 'Scale1_Net'])\n",
    "\n",
    "for item in subfolders_cleaned:\n",
    "    subpath = path + item + \"/func_nets/\"\n",
    "    files = os.listdir(subpath)\n",
    "    if \"corr_atlas-L2018_res-scale1.csv\" in files:\n",
    "        \n",
    "        with open(subpath + \"corr_atlas-L2018_res-scale1.csv\") as csvfile:\n",
    "            \n",
    "            mat=pd.read_csv(csvfile, sep=',',header=None)\n",
    "            scale1_sub_net= np.array(mat)\n",
    "        #print(np.shape(scale1_sub_net))\n",
    "            \n",
    "        if np.shape(scale1_sub_net) == (99, 99):\n",
    "        \n",
    "            new_row = {'Subj_ID': item, 'Scale1_Net':scale1_sub_net}\n",
    "            subj_nets = subj_nets.append(new_row, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6268320-7012-4e0a-8564-a500d2a3eb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_mats_temp = subj_nets.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ade0667-8faa-4db4-81c5-3e2cf889cc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_mats = subj_mats_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75baf84f-8108-4833-aafb-2f22e43cd9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(subj_mats_temp.shape[0]):\n",
    "    subj_mats[i][1] = clean_arr(subj_mats_temp[i][1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d3be89-24ec-4ff8-8044-438dd0b8fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subj_demo = pd.read_csv(\"subject_demographics.csv\")\n",
    "subj_demo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2003768e-4b05-4842-9b61-43fe4b8447b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_id = np.array(subj_demo.PTID)\n",
    "subj_diag = np.array(subj_demo.DX_bl)\n",
    "subj_gender = np.array(subj_demo.PTGENDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cddaf69e-abfa-47dd-bb2f-7c89c02941bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subj_demo.loc[subj_demo['PTGENDER'] == 'Male']\n",
    "#subj_demo.loc[subj_demo['PTGENDER'] == 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe385b15-a5d8-49ba-9df6-ec938b5f227c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency requires a distance matrix of weights between 0 and 1\n",
    "def inverse_RBF_old(W, with_inf=True, norm=False):\n",
    "    W_new = np.zeros(W.shape)\n",
    "    # Build a mask\n",
    "    valid_edges = np.nonzero(W)\n",
    "    mask = np.zeros(np.shape(W)).astype(bool)\n",
    "    mask[valid_edges] = True\n",
    "    zero_edges = np.argwhere(W==0)\n",
    "    \n",
    "    # Reverse RBF kernel\n",
    "    # Denominator has a small margin to make sure that ln does not reach 1\n",
    "    W_new[mask] = np.sqrt(-1 * np.log( W[mask]/(np.max(W[mask])+1e-5) ))\n",
    "    \n",
    "    # If we need to normalize between 0 and 1\n",
    "    if norm == True:\n",
    "        W_new = W_new/np.max(W_new[W_new<np.inf])\n",
    "    \n",
    "    # Fill in the non-edges as infinite distance\n",
    "    if with_inf == True:\n",
    "        W_new[~mask] = np.inf\n",
    "    \n",
    "    # Ensure that connections to self are 0 distance\n",
    "    np.fill_diagonal(W_new, 0)\n",
    "    \n",
    "    return W_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2e32b787-b033-4316-b486-5f6a3ed60774",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiency requires a distance matrix of weights between 0 and 1\n",
    "def inverse_RBF(W):\n",
    "    W_new = np.zeros(W.shape)\n",
    "    (m,n) = np.shape(W)\n",
    "    \n",
    "    for i in range(0,m):\n",
    "        for j in range(0,n):\n",
    "            W_new[i][j] = 1-W[i][j]\n",
    "    \n",
    "    \n",
    "    # Ensure that connections to self are 0 distance\n",
    "    np.fill_diagonal(W_new, 0)\n",
    "    \n",
    "    return W_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2ca5e06e-745d-4d89-b075-aad8969a2dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def PH_entropy(ripser_diagram, dim):\n",
    "    s_D = 0\n",
    "    E_D = 0\n",
    "    d_M = np.max(clean_arr(np.array(ripser_diagram[dim][:,1])))\n",
    "\n",
    "    for i in range(len(ripser_diagram[dim])):\n",
    "        \n",
    "        b_i = ripser_diagram[dim][i][0]\n",
    "        d_i = ripser_diagram[dim][i][1] if ripser_diagram[dim][i][1] != math.inf else d_M\n",
    "\n",
    "        p_i = d_i - b_i if d_i >= b_i else d_M\n",
    "        s_D += p_i\n",
    "    \n",
    "    for i in range(len(ripser_diagram[dim])):\n",
    "        b_i = ripser_diagram[dim][i][0]\n",
    "        d_i = ripser_diagram[dim][i][1] if ripser_diagram[dim][i][1] != math.inf else d_M\n",
    "        p_i = d_i - b_i if d_i >= b_i else d_M\n",
    "        s_i = p_i/s_D\n",
    "        if s_i <0: \n",
    "            print(b_i)\n",
    "            print(d_i)\n",
    "            print(s_i)\n",
    "            print(d_M)\n",
    "        E_D += s_i*(np.log(s_i)) # negative of entropy\n",
    "\n",
    "    return -E_D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b4a7ca18-9d1e-408d-b5d5-b898547b5ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for computing cocycles on N nodes\n",
    "\n",
    "# Inputs: \n",
    "#     nets: ((M x M) X N) vector of N networks sized (M x M)\n",
    "# Outputs:\n",
    "#   Vertex Importance Profile\n",
    "def compute_cocycles(subj_nets):\n",
    "    \n",
    "    #warnings.filterwarnings('ignore')\n",
    "    np.set_printoptions(precision=12)\n",
    "    np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "    \n",
    "    \n",
    "    #Avergae Persistence and Persistence Entropy\n",
    "    #Global_0D_features_AP_PE =[]\n",
    "    Global_1D_features_AP_PE =[]\n",
    "    Global_1D_features_AP_PE_df =['Average Persistence', 'Persistence Entropy']\n",
    "\n",
    "    #max_entropy_0D = 0\n",
    "    #min_entropy_0D = np.inf\n",
    "    \n",
    "    max_entropy_1D = 0\n",
    "    min_entropy_1D = np.inf\n",
    "\n",
    "\n",
    "     \n",
    "    #Vertex Importance Profile    \n",
    "    \n",
    "    # N = No of vertices/Nodes\n",
    "    \n",
    "    N = np.shape(subj_nets[0][1])[0]\n",
    "    \n",
    "    \n",
    "    #Number of Subjects/People\n",
    "    \n",
    "    Num_of_Subjs = subj_nets.shape[0]\n",
    "    \n",
    "    Vertex_Importance =list(range(0, N))\n",
    "    Vertex_Importance_NumCoCyles =list(range(0, N))\n",
    "    Vertex_Importance_NumCoCyles.insert(N, -1) # Last elemnt on the list holds the total number of cocycles for each subject \n",
    "    Sub_ID_Vertex_Importance_NumCoCycles =  ['Sub_ID'] + Vertex_Importance_NumCoCyles # first elemnt on the list holds the sub id\n",
    "    \n",
    "    #for i in tqdm(range(0,10)):\n",
    "    for i in tqdm(range(0,Num_of_Subjs)):\n",
    "    \n",
    "        #print(\"Subj ID: \", subj_nets[i][0])\n",
    "        net= subj_nets[i][1]\n",
    "        #print(net)\n",
    "\n",
    "        \n",
    "        \n",
    "        #using RBF kernel\n",
    "        \n",
    "        sub = inverse_RBF(net)\n",
    "        #print(sub)\n",
    "       \n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        #Using Ripser to extract persistence barcodes\n",
    "        ripser_diagram = ripser(net, distance_matrix=True)['dgms']\n",
    "        \n",
    "        #print(ripser_diagram)\n",
    "        \n",
    "        #Compute Average Persistence and Persistence Entropy\n",
    "        \n",
    "        \n",
    "        #PH0 Features\n",
    "        #birth_thresh_0D = clean_arr(np.array(ripser_diagram[0][:,0]))\n",
    "        #death_thresh_0D = clean_arr(np.array(ripser_diagram[0][:,1]))\n",
    "        #life_0D = np.subtract(death_thresh_0D, birth_thresh_0D)\n",
    "        #longest_persistence_0D = np.max(life_0D)\n",
    "        #mean_life_0D = np.mean(life_0D)\n",
    "        #ph_entropy_0D = PH_entropy(ripser_diagram, 0)\n",
    "        #Global_0D_features_AP_PE.append(np.concatenate(([mean_life_0D], [ph_entropy_0D])))\n",
    "    \n",
    "   \n",
    "    \n",
    "        #PH1 Features\n",
    "        birth_thresh_1D = clean_arr(np.array(ripser_diagram[1][:,0]))\n",
    "        death_thresh_1D = clean_arr(np.array(ripser_diagram[1][:,1]))\n",
    "        life_1D = np.subtract(death_thresh_1D, birth_thresh_1D)\n",
    "        longest_persistence_1D = np.max(life_1D)\n",
    "        mean_life_1D = np.mean(life_1D)\n",
    "        ph_entropy_1D = PH_entropy(ripser_diagram, 1)\n",
    "        Global_1D_features_AP_PE.append(np.concatenate(([mean_life_1D], [ph_entropy_1D])))\n",
    "    \n",
    "       \n",
    "                \n",
    "        sub_Vertex_Importance = [0]*N #initialize with zeros for each subjects\n",
    "        #print(\"Initialized Vertex Importance Profile =\", sub_Vertex_Importance)\n",
    "        \n",
    "        \n",
    "        #For each permutation of nodes compute the VIP\n",
    "        \n",
    "        \n",
    "        Avg_sub_Vertex_Importance = np.array([0]*N, float)\n",
    "        \n",
    "        for j in range(0,N):\n",
    "            #print(\"j=\", j)\n",
    "            sub_temp=sub\n",
    "            sub_temp[[1, j],:] = sub_temp[[j, 1],:]\n",
    "            sub_temp[:,[1, j]] = sub_temp[:,[j, 1]]\n",
    "            np.fill_diagonal(sub_temp, 0)\n",
    "            \n",
    "            result = ripser(sub_temp, distance_matrix=True, do_cocycles=True)\n",
    "            diagrams = result['dgms']\n",
    "            D = result['dperm2all']\n",
    "            cocycles = result['cocycles']\n",
    "           \n",
    "        \n",
    "            #print(diagrams)\n",
    "            #print(cocycles)\n",
    "        \n",
    "            #Visualization\n",
    "            \n",
    "            #dgm1 = diagrams[1]\n",
    "            #idx = np.argmax(dgm1[:, 1] - dgm1[:, 0])\n",
    "            #plot_diagrams(diagrams, show = False)\n",
    "            #plt.scatter(dgm1[idx, 0], dgm1[idx, 1], 20, 'k', 'x')\n",
    "            #plt.title(\"Max 1D birth = %.3g, death = %.3g\"%(dgm1[idx, 0], dgm1[idx, 1]))\n",
    "            #plt.show()\n",
    "        \n",
    "\n",
    "            \n",
    "        \n",
    "            #print(\"Number of 1-dim cocyles :\", len(cocycles[1]))\n",
    "            #print(\"1-dim cocyles :\", cocycles[1])\n",
    "            \n",
    "            \n",
    "            sub_Vertex_Importance = [0]*N\n",
    "            for k,ar in enumerate(cocycles[1]):\n",
    "            \n",
    "                size_ar = len(ar)\n",
    "                \n",
    "                for rep_cyc in ar: \n",
    "                    for vertex in rep_cyc:\n",
    "                    \n",
    "                        sub_Vertex_Importance[vertex] = min(round(sub_Vertex_Importance[vertex]+round((1/size_ar), 5), 5), k+1)\n",
    "            \n",
    "            temp_vertex = sub_Vertex_Importance[j]\n",
    "            sub_Vertex_Importance[j] = sub_Vertex_Importance[1]\n",
    "            sub_Vertex_Importance[1] = temp_vertex\n",
    "            \n",
    "            #print(sub_Vertex_Importance)\n",
    "            Avg_sub_Vertex_Importance += np.array(sub_Vertex_Importance)\n",
    "            \n",
    "        norm_arr = [len(cocycles[1])]*N # normalizing array\n",
    "            \n",
    "        Avg_sub_Vertex_Importance = np.subtract(Avg_sub_Vertex_Importance, norm_arr)\n",
    "        Avg_sub_Vertex_Importance = Avg_sub_Vertex_Importance/np.max(Avg_sub_Vertex_Importance)\n",
    "        Avg_sub_Vertex_Importance = np.array(Avg_sub_Vertex_Importance, dtype = np.float64)\n",
    "        Avg_sub_Vertex_Importance = np.round_(Avg_sub_Vertex_Importance, decimals = 5)\n",
    "        Avg_sub_Vertex_Importance = np.array(Avg_sub_Vertex_Importance, dtype = np.float64)\n",
    "        Avg_sub_Vertex_Importance_NumCoCycles = np.concatenate((Avg_sub_Vertex_Importance, np.array([len(cocycles[1])])), axis=0)\n",
    "        \n",
    "        \n",
    "        #adding subject ID \n",
    "        \n",
    "        sub_id= subj_nets[i][0]\n",
    "        \n",
    "        Avg_Sub_ID_Vertex_Importance_NumCoCycles = np.concatenate((np.array([sub_id]), Avg_sub_Vertex_Importance_NumCoCycles), axis=0)\n",
    "        \n",
    "        \n",
    "       \n",
    "        #print(\"VIP=\",Avg_sub_Vertex_Importance)\n",
    "                 \n",
    "        Vertex_Importance = np.vstack((Vertex_Importance, Avg_sub_Vertex_Importance ))\n",
    "        Vertex_Importance_NumCoCyles = np.vstack((Vertex_Importance_NumCoCyles, Avg_sub_Vertex_Importance_NumCoCycles))\n",
    "        Sub_ID_Vertex_Importance_NumCoCycles = np.vstack((Sub_ID_Vertex_Importance_NumCoCycles, Avg_Sub_ID_Vertex_Importance_NumCoCycles))\n",
    "        \n",
    "        \n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        #break;\n",
    "    \n",
    "    #return(Global_1D_features_AP_PE, Vertex_Importance_NumCoCyles)\n",
    "    return(Global_1D_features_AP_PE, Sub_ID_Vertex_Importance_NumCoCycles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "30d149a1-e7dc-42e0-885e-e71fcb167ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 410/410 [04:43<00:00,  1.45it/s]\n"
     ]
    }
   ],
   "source": [
    "Global_1D_features_AP_PE, Vertex_Importance_NumCoCyles = compute_cocycles(subj_mats)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ed21c2cc-e582-4fd2-8ca5-0ca7fc05be05",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "#print(Global_1D_features_AP_PE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b6b61dd7-04c4-460b-b85b-ca58aae40427",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(formatter={'float_kind':'{:f}'.format})\n",
    "#print(Vertex_Importance_NumCoCyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "549edf53-691b-4906-bb9b-5b801b6172fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ADNI_fMRI_Global_Vertex_Importance_NumCoCyles = pd.DataFrame(Vertex_Importance_NumCoCyles)\n",
    "ADNI_fMRI_Global_Vertex_Importance_NumCoCyles.to_csv(\"ADNI_fMRI_Global_Vertex_Importance_NumCoCyles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "501b2ba1-6266-427c-9843-3611bab3265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(ADNI_fMRI_Global_Vertex_Importance_NumCoCyles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "78c89dfa-8d21-4138-8238-df3c551e7d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_VIP = open(\"ADNI_fMRI_Global_Vertex_Importance_NumCoCyles_07312023.npy\", 'rb')\n",
    "np.save(file_VIP, np.array(Vertex_Importance_NumCoCyles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "96a0d1c2-8c86-4834-88af-1e38539ac28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_AP_PE= open(\"ADNI_fMRI_Global_1D_features_AP_PE_07312023.npy\", 'rb')\n",
    "np.save(file_AP_PE, np.array(Global_1D_features_AP_PE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "604180f8-81ab-4651-a71b-2b991d0db518",
   "metadata": {},
   "outputs": [],
   "source": [
    "VIP = np.load(\"ADNI_fMRI_Global_Vertex_Importance_NumCoCyles_07312023.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c7172fb-b4af-4161-9ad5-3633fb1f62a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = pd.read_csv('subject_demographics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "69e9adf1-b32d-4098-82ae-9546662c417c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410\n"
     ]
    }
   ],
   "source": [
    "sub_ids = VIP[:,0]\n",
    "n = len(sub_ids)\n",
    "sub_ids = sub_ids[1: n]\n",
    "print(len(sub_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6b72b345-2a30-4708-8549-77cec9ade75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e6dee4e9-9099-4965-877c-de490f1c7381",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_demo = demo[demo[\"PTID\"].isin(sub_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92abfe85-819e-4cdf-8135-853172bb5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(filtered_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a13889b-ca56-4c65-89f6-6d804950b524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                PTID\n",
      "DX_bl PTGENDER      \n",
      "AD    Female       8\n",
      "      Male        14\n",
      "CN    Female      58\n",
      "      Male        56\n",
      "EMCI  Female      51\n",
      "      Male        60\n",
      "LMCI  Female      38\n",
      "      Male        48\n",
      "SMC   Female      45\n",
      "      Male        32\n"
     ]
    }
   ],
   "source": [
    "subjects = filtered_demo[['PTID', 'DX_bl', 'PTGENDER']].groupby(['DX_bl', 'PTGENDER'])\n",
    "print(subjects.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1f5259d-c731-4fa1-a325-53e06ff25904",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_age = filtered_demo[['PTID', 'DX_bl', 'AGE']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fb0a390-4d6f-4298-b58f-8d3587c8c4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(demo_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "27035b2c-0d06-475c-975c-52197703fef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = demo_age.groupby(['DX_bl'], as_index=False).agg({'AGE':['mean','std']})\n",
    "display(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c98f3d78-db4f-4aee-bb60-98c9aa3afa89",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_age_edu = filtered_demo[['PTID', 'DX_bl', 'AGE', 'PTEDUCAT']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "377b8571-eae7-4aa8-90e8-80c85360e52c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>DX_bl</th>\n",
       "      <th colspan=\"2\" halign=\"left\">PTEDUCAT</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AD</td>\n",
       "      <td>15.772727</td>\n",
       "      <td>2.860766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN</td>\n",
       "      <td>16.421053</td>\n",
       "      <td>2.555212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EMCI</td>\n",
       "      <td>16.378378</td>\n",
       "      <td>2.504738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LMCI</td>\n",
       "      <td>16.104651</td>\n",
       "      <td>2.731210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMC</td>\n",
       "      <td>16.402597</td>\n",
       "      <td>2.466938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  DX_bl   PTEDUCAT          \n",
       "              mean       std\n",
       "0    AD  15.772727  2.860766\n",
       "1    CN  16.421053  2.555212\n",
       "2  EMCI  16.378378  2.504738\n",
       "3  LMCI  16.104651  2.731210\n",
       "4   SMC  16.402597  2.466938"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "output = demo_age_edu.groupby(['DX_bl'], as_index=False).agg({'PTEDUCAT':['mean','std']})\n",
    "display(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
